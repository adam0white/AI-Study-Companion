# AI Study Companion

An intelligent AI-powered study companion built on Cloudflare's Developer Platform.

## Tech Stack

- **Runtime**: Cloudflare Workers
- **Frontend**: React + Vite + TypeScript
- **Styling**: Tailwind CSS + shadcn/ui
- **State Management**: Durable Objects
- **Database**: Cloudflare D1 (SQLite)
- **Storage**: Cloudflare R2
- **Authentication**: Clerk

## Project Status

‚úÖ **Story 1.1 Complete** - Foundation setup ready  
üöÄ **Deployed**: https://study.adamwhite.work  
‚è≥ **Next**: Story 1.2 - Durable Object Implementation

## Security

Authentication is handled by [Clerk](https://clerk.com) with proper JWT signature verification using JWKS. All API endpoints require valid authentication tokens.

## Getting Started

### Prerequisites

- Node.js (v18 or higher)
- npm or pnpm
- Cloudflare account (free tier available)
- Clerk account (free tier available)

### Initial Setup (Completed)

The following has been set up:

- ‚úÖ Project structure with TypeScript
- ‚úÖ Build system (Vite + Wrangler)
- ‚úÖ All dependencies installed
- ‚úÖ Tailwind CSS + shadcn/ui configured
- ‚úÖ Git repository initialized
- ‚úÖ Worker entry point with health check
- ‚úÖ Durable Objects structure

### Manual Steps Required

#### 1. Cloudflare Authentication

```bash
# Login to Cloudflare
npx wrangler login

# Verify authentication
npx wrangler whoami
```

#### 2. Cloudflare Resources (Auto-Provisioned)

**Good news!** If you're using Wrangler v4.45+ (which this project uses), D1 and R2 resources are **automatically provisioned** on your first deploy. No manual creation needed!

The first time you run `npm run deploy`, Wrangler will:
- ‚ú® Automatically create the D1 database: `ai-study-companion-db`
- ‚ú® Automatically create the R2 bucket: `ai-study-companion-storage`
- ‚ú® Write the resource IDs back to your `wrangler.jsonc`

**Manual Creation (Optional):**

If you prefer to create resources manually first, you can:

```bash
# Optional: Create D1 database manually
npx wrangler d1 create ai-study-companion-db
# Copy the database_id from output and update wrangler.jsonc

# Optional: Create R2 bucket manually
npx wrangler r2 bucket create ai-study-companion-storage
```

**Learn more:** [Automatic Resource Provisioning (Cloudflare, Oct 2024)](https://developers.cloudflare.com/changelog/2025-10-24-automatic-resource-provisioning/)

#### 3. Set Up Clerk Authentication

1. Create account at [clerk.com](https://clerk.com)
2. Create new application
3. Configure environment variables:

**Frontend (.env file):**
```bash
# Create .env file in project root
VITE_CLERK_PUBLISHABLE_KEY=pk_test_YOUR_KEY
```

**Backend (wrangler.jsonc):**
```jsonc
{
  "vars": {
    "CLERK_PUBLISHABLE_KEY": "pk_test_YOUR_KEY"
  }
}
```

**Secret Keys (Cloudflare Secrets):**
```bash
# Store secret key in Cloudflare (optional - only needed for certain Clerk features)
npx wrangler secret put CLERK_SECRET_KEY
# Paste your secret key when prompted
```

**Important:** Never commit `.env` or secret keys to version control.

#### 4. Local Development

```bash
# Install dependencies (if not already done)
npm install

# Start local development server
npm run dev
```

The dev server will start on `http://localhost:8787`

#### 5. Deploy to Cloudflare

```bash
# Build the project
npm run build

# Deploy to Cloudflare
npm run deploy
```

## Project Structure

```
src/
‚îú‚îÄ‚îÄ worker.ts                    # Cloudflare Worker entry point
‚îú‚îÄ‚îÄ durable-objects/            # Durable Object classes
‚îÇ   ‚îî‚îÄ‚îÄ StudentCompanion.ts
‚îú‚îÄ‚îÄ components/                 # React components
‚îÇ   ‚îú‚îÄ‚îÄ ui/                    # shadcn/ui components
‚îÇ   ‚îú‚îÄ‚îÄ chat/                  # Chat interface
‚îÇ   ‚îú‚îÄ‚îÄ practice/              # Practice questions
‚îÇ   ‚îú‚îÄ‚îÄ progress/              # Progress tracking
‚îÇ   ‚îî‚îÄ‚îÄ layout/                # Layout components
‚îú‚îÄ‚îÄ lib/                       # Utility libraries
‚îÇ   ‚îú‚îÄ‚îÄ rpc/                   # RPC client
‚îÇ   ‚îú‚îÄ‚îÄ db/                    # Database utilities
‚îÇ   ‚îú‚îÄ‚îÄ ai/                    # AI integration
‚îÇ   ‚îú‚îÄ‚îÄ auth.ts                # Authentication utilities
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts               # General utilities
‚îú‚îÄ‚îÄ types/                     # TypeScript type definitions
‚îî‚îÄ‚îÄ hooks/                     # React hooks
```

## Available Scripts

- `npm run dev` - Start local development server with Wrangler
- `npm run build` - Build for production
- `npm run deploy` - Deploy to Cloudflare
- `npm run lint` - Run ESLint
- `npm run preview` - Preview production build locally

## Health Check

Once deployed, verify the worker is running:

```bash
curl https://your-worker-url.workers.dev/health
```

Expected response:
```json
{
  "status": "ok",
  "timestamp": "2025-11-07T...",
  "service": "ai-study-companion"
}
```

## Next Steps

After completing the setup:

1. Implement full Durable Objects functionality (Story 1.2)
2. Set up database schema (Story 1.3)
3. Build UI components (Stories 1.4-1.6)
4. Integrate memory system (Story 1.7)

## Memory Intelligence System

The AI Study Companion features a sophisticated **dual-memory architecture** that enables true personalization through automatic knowledge consolidation.

### How It Works

**Short-Term Memory** ‚Üí **Automatic Consolidation** ‚Üí **Long-Term Memory** ‚Üí **Personalized Responses**

1. **Session Ingestion**: Tutoring sessions are stored as short-term memories
2. **Automatic Consolidation**: After 4 hours, an alarm triggers LLM-powered analysis
3. **Knowledge Extraction**: AI extracts background, strengths, struggles, and goals
4. **Long-Term Storage**: Consolidated insights persist in the student's profile
5. **Personalized Responses**: Chat responses reference the student's learning journey

### The Magic Moment

When a student returns after multiple sessions, the companion remembers:

> "I remember discriminants were confusing for you at first, but you made incredible progress! You went from struggling with the basic concept to mastering all three types of roots in just a few days."

This personalization is powered by:
- **Dual-Memory System**: Ephemeral short-term + permanent long-term storage
- **LLM Consolidation**: AI analyzes sessions to extract structured insights
- **Durable Object Alarms**: Cloudflare's "sleep" functionality for scheduled processing
- **In-Memory Caching**: Fast retrieval with 10-minute cache for long-term memory

### Key Features

**üìä Profile Card** - Displays consolidated learning profile (background, goals, strengths, areas for growth)

**üìÖ Recent Sessions** - Shows session history with consolidation status

**‚ö° Memory Status** - Displays last consolidation and pending memories

**‚ú® Personalization Badges** - Highlights when responses reference student's memory

### Learn More

See the complete [Memory Intelligence Documentation](./docs/memory-intelligence.md) for:
- Detailed architecture and flow diagrams
- Consolidation process deep-dive
- Performance optimizations
- Demo data and testing guides

## Documentation

- [Product Requirements](./docs/PRD.md)
- [Architecture](./docs/architecture.md)
- [UX Design](./docs/ux-design-specification.md)
- [Epic Breakdown](./docs/epics.md)
- [Memory Intelligence System](./docs/memory-intelligence.md) ‚≠ê **New!**

## License

Private project

